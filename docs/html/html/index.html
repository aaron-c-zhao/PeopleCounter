<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.15"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>People counter: Main Page</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(initResizable);
/* @license-end */</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">People counter
   &#160;<span id="projectnumber">0.2</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.15 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('index.html','');});
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">People counter Documentation</div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1>People counter</h1>
<p>this repo consist of 2 main parts, the people counting module and the test harness to run it. The poeplecounter module in peoplecounter.c is supposed to be hardware independent and really to be implemented on an embedded system. Because the team didn't have access to the hardware and firmware to test the module, a testing harness was created. This harness will go through recorded sensor data in ./data and call the module on each frame, according to the api. This way we could test and improve the pipeline.</p>
<h2>Documentation</h2>
<p>For documenting the code in this repo doxygen was used. This generated interactive html documentation. The generated html can be found in "./docs/html/html/index.html". This can also be regenerated by running the doxygen command in the root folder.</p>
<h1>PEOPLE COUNTER IP PIPELINE TESTING HARNESS</h1>
<p>This program was made to run and test the image processing pipeline of the people counter project.</p>
<h2>HOW TO INSTALL AND RUN THE HARNESS</h2>
<h3>SUPPORTED ENVIRONMENT</h3>
<ul>
<li>Mac Darwin</li>
<li>Linux</li>
</ul>
<h3>DEPENDENCIES</h3>
<ol type="1">
<li>CMake: &gt; 3.15</li>
<li>OpenCV</li>
</ol>
<ul>
<li>GCC 4.4.x or later</li>
<li>Git</li>
<li>GTK+2.x or higher</li>
<li>pkg-config</li>
<li>Python2.6 or later</li>
<li>ffmpeg or libav development packages: libavcodec-dev, libavformat-dev, libswscale-dev</li>
</ul>
<ol type="1">
<li>Doxygen 1.8.15(optional)</li>
</ol>
<h3>INSTRUCTIONS</h3>
<h4>CONFIGURATION</h4>
<p>After cloning this repository onto your local machine, first you need to configure the harness code and header file of the pipeline which could be accomplished by modify these two files:</p><ul>
<li>harness_config.json<ul>
<li>parameters: the parameters of the ip pipeline that will affect its affectiveness<ul>
<li>kernel_1: gaussian blur kernel 1, default value 5</li>
<li>threshold: the threshold applied when binarize the image, defaule value 32</li>
<li>max_area: the maximum area of a blob that is allowed, used as a trigger of updating threshold to detect overly large blobs, default value 18</li>
</ul>
</li>
<li>harness_setup: configurations of the harness code, this won't affect the pipeline<ul>
<li>width: image width which will affect the image shown in the window</li>
<li>height: image height which will affect the image shown in the window</li>
<li>llimit: the lower limit applied when map the floating point temperature figure to 8bit grey value</li>
<li>hlimit: the upper limit applied when map the floating point temperature figure to 8bit grey value</li>
<li>frame_rate: the frame rate of the video, this combined with the FRAME_RATE seeting in header_config.txt will decide the step of the image pointer.</li>
</ul>
</li>
</ul>
</li>
<li>header_config.txt<ul>
<li>SENSOR_IMAGE_WIDTH: the width of the image to be processed by the pipeline, default value 32</li>
<li>SENSOR_IMAGE_HEIGHT: the height of the image to be processed by the pipeline, default valut 24</li>
<li>FRAME_RATE: the frame rate that the pipeline will work with.</li>
<li>RECTS_MAX_SIZE: the maximum array size of the rects array</li>
<li>QUEUE_SIZE: the maximum array size of the queue for breach first search</li>
<li>CT_MAX_DISAPPEARED: the maximum frames in which a blob is allowed to disappear, after that the BID(blob id) will be reallocated</li>
<li>CT_MAX_DISTANCE: the maximum distance that a blob is allowed to jump between frames</li>
<li>TRACKABLE_OBJECT_MAX_SIZE: the maximum number of blobs or people that the pipeline could trace at the same time</li>
</ul>
</li>
</ul>
<h4>RUN THE PIPELINE LINE</h4>
<p>If you agree with the current configuration, then you can run the pipeline by following the instructions below:</p><ol type="1">
<li>change directory(cd) into the source folder of the project(PeopleCounter/)</li>
<li>run the script make.sh(./make.sh)</li>
<li>cd into the build/ folder.</li>
<li>run the executable(PeopleCounter) with the argument of the path of the json file(./PeopleCounter ../data/mlx90640/vertical/.....)</li>
</ol>
<h4>INTERACTION WITH THE HARNESS</h4>
<p>The harness will run the pipeline while displaying the images frame by frame. Press any key to go to the next frame. Press Ctrl+C on the terminal to exit.</p>
<h4>OUTPUT OF THE HARNESS</h4>
<p>The harness will output the following:</p><ul>
<li>list of currently tracked objects, including its ID, centroid position and disappeared frame count</li>
<li>current frame number</li>
<li>the number of people that went up and down in this frame</li>
<li>the estimate count of people in the room</li>
</ul>
<h2>RECOMMANDATIONS FOR FURTHER DEVELOPING</h2>
<p>In <a class="el" href="tracking_research.html">People tracking research</a> and <a class="el" href="detection_research.html">People detection research</a> all the possible research that could still be done is listed.</p>
<h3>CODE OPTIMAZATION</h3>
<ol type="1">
<li>Hardcode the LoG kernel For the sake of easy testing with new parameters, the LoG kernel is generated by the harness code each time with the kernel size that have been set. In the final product, it should be hardcoded into the pipeline to reduce the computation.</li>
<li>Use the inplace calculation The functions in the pipleline are designed to be able to do inplace calculations. So no extra data structure is needed other than the one that is passed in by the firmware. But now, for displaying the intermedia result, an extra log_mat was introduced which should be replaced by the frame_mat to reduce the space requirement.</li>
<li>Ohters During the processing of the image, each pixel will be iterated several times. But not all of the iterations are necessary, due to the time constraint, we can not optimize it to the optimal. So coners could be cut there.</li>
</ol>
<h3>ALGORITHM OPTIMAZATION</h3>
<ol type="1">
<li>People detection The pipeline now using the Laplacian of Gaussian algorithm to extract and detect blobs which is twice efficient than the previous thresholding + border tracing. But algorithms like <a href="./docs/watershed.pdf">Watershed</a>, and Gaussian mixture have the potential to be more efficient.</li>
<li>People tracking The algorithm currently being used to track blobs is the nearest neighbour method, which is a basic tracking method. More advanced methods like Kalman filter will be more robust than the current one. But on the other hand, the robustness comes with a price that it will add a considerable amount of complexity to the system.</li>
<li>Background substraction For now the pipeline takes the first frame as the background(In the final product, this should be the first frame of each time the device is waken up by the PIR). This way has a fatal flaw which is that it relays on the assumption that the Melexis sensor could be waken up early enough that there's still no person in the FOV. To sovle this Eigen backgound, <a href="./docs/people_detection.pdf">Morphological background substraction</a> might be worthwhile to look into. </li>
</ol>
</div></div><!-- PageDoc -->
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.15 </li>
  </ul>
</div>
</body>
</html>
